{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Python function that performs linear regression using gradient descent. \n",
    "\n",
    "The function should take NumPy arrays X (features with a column of ones for the intercept) and y (target) as input, \n",
    "\n",
    "along with learning rate alpha and the number of iterations, and return the coefficients of the linear regression model as a NumPy array. \n",
    "\n",
    "Round your answer to four decimal places. -0.0 is a valid result for rounding a very small number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:18\u001b[1;36m\u001b[0m\n\u001b[1;33m    (m, n) = X.shape\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def linear_regression_gradient_descent(X: np.ndarray, y: np.ndarray, alpha: float, iterations: int) -> np.ndarray:\n",
    "     \"\"\"\n",
    "  Performs linear regression using gradient descent.\n",
    "\n",
    "  Args:\n",
    "      X: A NumPy array representing the feature matrix with a column of ones for the intercept.\n",
    "      y: A NumPy array representing the target vector.\n",
    "      alpha: The learning rate.\n",
    "      iterations: The number of iterations for gradient descent.\n",
    "\n",
    "  Returns:\n",
    "      A NumPy array containing the coefficients of the linear regression model \n",
    "      rounded to four decimal places.\n",
    "  \"\"\"\n",
    "\n",
    "  # Get number of training examples and number of features\n",
    "  m, n = X.shape\n",
    "\n",
    "  # Initialize coefficients with zeros\n",
    "  theta = np.zeros((n, 1))\n",
    "\n",
    "# Perform gradient descent for specified iterations\n",
    "  for _ in range(iterations):\n",
    "    # Calculate predictions\n",
    "    predictions = X.dot(theta)\n",
    "\n",
    "    # Calculate errors\n",
    "    errors = predictions - y\n",
    "\n",
    "    # Update coefficients using gradient descent rule\n",
    "    theta = theta - alpha * (1/m) * X.T.dot(errors)\n",
    "\n",
    "  # Round coefficients to four decimal places\n",
    "return np.round(theta, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([[1, 1], [1, 2], [1, 3]])\n",
    "y = np.array([1, 2, 3]) \n",
    "alpha = 0.01 \n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = X.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
